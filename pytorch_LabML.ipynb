{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">\n",
       "\n",
       "<strong><span style=\"text-decoration: underline\">=> mnist_labml_tracker</span></strong>: <span style=\"color: #208FFB\">2ada9afa5e5611ebac47acde48001122</span>\n",
       "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"test\"</span></strong>\n",
       "<strong><span style=\"color: #DDB62B\">     938:  </span></strong> loss.train: <strong>0.234214</strong> loss.valid: <strong>0.190915</strong> accuracy.valid: <strong> 94.1100</strong>\n",
       "<strong><span style=\"color: #DDB62B\">     938:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.234214</span> loss.valid: <span style=\"color: #C5C1B4\">0.190915</span> accuracy.valid: <span style=\"color: #C5C1B4\"> 94.1100</span> loss.test: <strong> 80.0000</strong> accuracy.test: <strong> 1.23000</strong></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from labml import lab, tracker, experiment, logger\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple convolutional neural network we use for this sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, device, train_log_interval):\n",
    "    \"\"\"This is the training code\"\"\"\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # **✨ Increment the global step**\n",
    "        tracker.add_global_step()\n",
    "        # **✨ Store stats in the tracker**\n",
    "        tracker.add({'loss.train': loss})\n",
    "\n",
    "        #\n",
    "        if batch_idx % train_log_interval == 0:\n",
    "            # **✨ Save added stats**\n",
    "            tracker.add(model=model)\n",
    "            tracker.save()\n",
    "\n",
    "\n",
    "def validate(model, valid_loader, device):\n",
    "    \"\"\"This is the validation code\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            valid_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "\n",
    "    # **Save stats**\n",
    "    tracker.save({'loss.valid': valid_loss, 'accuracy.valid': valid_accuracy})\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ✨ Set the types of the stats/indicators.\n",
    "    # They default to scalars if not specified\n",
    "    tracker.set_queue('loss.train', 20, True)\n",
    "    tracker.set_histogram('loss.valid', True)\n",
    "    tracker.set_scalar('accuracy.valid', True)\n",
    "\n",
    "    # Configurations\n",
    "    configs = {\n",
    "        'epochs': 1,\n",
    "        'train_batch_size': 64,\n",
    "        'valid_batch_size': 100,\n",
    "        'use_cuda': True,\n",
    "        'seed': 5,\n",
    "        'train_log_interval': 10,\n",
    "        'learning_rate': 0.01,\n",
    "    }\n",
    "\n",
    "    is_cuda = configs['use_cuda'] and torch.cuda.is_available()\n",
    "    if not is_cuda:\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:0\")\n",
    "\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(str(lab.get_data_path()),\n",
    "                       train=True,\n",
    "                       download=True,\n",
    "                       transform=data_transform),\n",
    "        batch_size=configs['train_batch_size'], shuffle=True)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(str(lab.get_data_path()),\n",
    "                       train=False,\n",
    "                       download=True,\n",
    "                       transform=data_transform),\n",
    "        batch_size=configs['valid_batch_size'], shuffle=False)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=configs['learning_rate'])\n",
    "\n",
    "    torch.manual_seed(configs['seed'])\n",
    "\n",
    "    # ✨ Create the experiment\n",
    "    experiment.create(name='=> mnist_labml_tracker',python_file=\"pytorch_LabML.ipynb\")\n",
    "\n",
    "    # ✨ Save configurations\n",
    "    experiment.configs(configs)\n",
    "\n",
    "    # ✨ Set PyTorch models for checkpoint saving and loading\n",
    "    experiment.add_pytorch_models(dict(model=model))\n",
    "\n",
    "    # ✨ Start and monitor the experiment\n",
    "    with experiment.start():\n",
    "        for epoch in range(1, configs['epochs'] + 1):\n",
    "            train(model, optimizer, train_loader, device, configs['train_log_interval'])\n",
    "            validate(model, valid_loader, device)\n",
    "            logger.log()\n",
    "\n",
    "        tracker.save({'loss.test': 80.0, 'accuracy.test': 1.23})\n",
    "    # ✨ Save the models\n",
    "    experiment.save_checkpoint()\n",
    "    \n",
    "\n",
    "\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
